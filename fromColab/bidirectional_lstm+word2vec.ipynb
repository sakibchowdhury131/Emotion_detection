{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bidirectional_lstm+word2vec.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPEXnyUsdkTtI9Tk+9DrVQk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"eB2ad8Yy8jUm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"899652c4-6088-4539-90b9-7ac22de1f331","executionInfo":{"status":"ok","timestamp":1589355145152,"user_tz":-360,"elapsed":6769,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":["pip install num2words"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting num2words\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n","\r\u001b[K     |███▎                            | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n","Installing collected packages: num2words\n","Successfully installed num2words-0.5.10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o5Gn9M-U8o-D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"f202e282-9a1f-4f8f-f3af-04844c35f916","executionInfo":{"status":"ok","timestamp":1589355136781,"user_tz":-360,"elapsed":3190,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"DvxnaQzW8u1W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":727},"outputId":"c67a2ead-7579-4d96-d599-518644c7ae80","executionInfo":{"status":"error","timestamp":1589357081910,"user_tz":-360,"elapsed":1316,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat May  9 22:34:44 2020\n","\n","@author: sakib\n","\n","\"\"\"\n","\n","\n","#change base directory\n","import os\n","\n","base_path=r'/content'\n","working_directory = '/content'\n","data_folder = r'/content/data'\n","embedding_folder = r'/content/embeddings'\n","models_folder = r'/content/models'\n","model_directory = working_directory+'/'+'models'\n","\n","\n","def change_base_dir(base_dir_path):\n","    \"\"\" Change the working directopry of the code\"\"\"\n","    \n","    if not os.path.exists(base_dir_path):\n","        print ('creating directory', base_dir_path)\n","        os.makedirs(base_dir_path)\n","    print ('Changing base directory to ', base_dir_path)\n","    os.chdir(base_dir_path)\n"," \n","      \n","\n","# base_folder='data'\n","# base_dir_path=base_path+'/'+base_folder\n","# change_base_dir(base_dir_path)\n","# download_data.extract_file('/media/sakib/alpha/work/EmotionDetectionDir/git/data/glove.6B.zip')\n","\n","\n","\n","change_base_dir(base_path)\n","if not os.path.exists(data_folder):\n","        os.makedirs(data_folder)\n","if not os.path.exists(embedding_folder):\n","        os.makedirs(embedding_folder)\n","if not os.path.exists(models_folder):\n","        os.makedirs(models_folder)\n","  \n","#loading necessary files\n","from load_preprocess import load_data,load_data_embedding\n","from load_preprocess import preprocess_data\n","from load_preprocess import read_labels\n","import word2vec\n","import sswe\n","import glove_file\n","import designing_network\n","import download_data\n","\n","\n","#importing libraries\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","\n","\n","\n","# Download data\n","\n","print('Checking requirements:')\n","download_data.download_data(base_path = base_path)\n","\n","#loading data\n","print('Step1: Loading Embedding training Dataset...')\n","\n","\n","dataset_embedding = load_data_embedding(working_directory+'/data/'+'training.1600000.processed.noemoticon.csv')\n","print('Step2: Shuffling data...')\n","dataset_embedding = dataset_embedding.sample(frac=1) # reshuffling the data\n","print('Step3: Preprocessing the texts...')\n","texts = preprocess_data(dataset_embedding)\n","labels = read_labels(dataset_embedding)\n","\n","\n","# building word2vec model\n","print('Step4: Building word2vec model...')\n","EMBEDDING_DIM = 100\n","w2v = word2vec.create_word2vec(directory = working_directory+'/'+'embeddings',texts = texts ,min_count = 1,EMBEDDING_DIM = EMBEDDING_DIM)\n","\n","\n","\n","# loading twitter_dataset_small\n","print('Step6: Loading Twitter Dataset')\n","dataset = load_data(working_directory+'/'+'data'+'/'+'Tweets.csv')\n","texts = preprocess_data(dataset)\n","y = pd.get_dummies(dataset['Label']).values\n","\n","\n","\n","#tokenizing\n","print ('Step7: Tokenizing...')\n","\n","tokens = []\n","for line in texts:\n","    words = word_tokenize(line)\n","    tokens.append(words)\n","\n","\n","\n","tokenizer_obj = Tokenizer()\n","tokenizer_obj.fit_on_texts(tokens)\n","sequences = tokenizer_obj.texts_to_sequences(tokens)\n","\n","\n","#padding\n","print ('Step8: Padding...')\n","tokenizer_word_index = tokenizer_obj.word_index\n","max_length = 150\n","review_pad = pad_sequences(sequences, maxlen = max_length)\n","\n","\n","\n","# train test split\n","print('Step9: train and test set generation...')\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(review_pad, y, test_size = 0.20, random_state = 0)\n","\n","\n","# word2vec Embedding Matrix\n","print('Step10: Generating word2vec embedding matrix...')\n","num_words = len(tokenizer_word_index) + 1\n","embedding_matrix_w2v = word2vec.load_word2vec(working_directory+'/'+'embeddings'+'/'+'embeddings_w2v.txt', tokenizer_word_index=tokenizer_word_index, EMBEDDING_DIM=EMBEDDING_DIM)\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Changing base directory to  /content\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Checking requirements:\n","Downloading stanford data\n","Extracting stanford data\n","Downloading Twitter data\n","Downloading glove model...\n","Extracting glove data\n","Step1: Loading Embedding training Dataset...\n","Step2: Shuffling data...\n","Step3: Preprocessing the texts...\n","Step4: Building word2vec model...\n","Saving word2vec model in the disk\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["Step6: Loading Twitter Dataset\n","Step7: Tokenizing...\n","Step8: Padding...\n","Step9: train and test set generation...\n","Step10: Generating word2vec embedding matrix...\n","Step11: designing lstm+w2v model...\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-dd070f0ecd1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step11: designing lstm+w2v model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mw2v_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_architecture_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0mw2v_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_network_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w2v_lstm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/designing_network.py\u001b[0m in \u001b[0;36mmodel_architecture_word2vec\u001b[0;34m(embedding_matrix, num_words, EMBEDDING_DIM, max_length)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m196\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"w-GW7UQ-FP1b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":816},"outputId":"9a2b6c93-6460-4e2a-fe0b-9e80312295e2","executionInfo":{"status":"ok","timestamp":1589359090752,"user_tz":-360,"elapsed":642435,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":["import designing_networksssss\n","# training the word2vec model with lstm\n","print('Step11: designing lstm+w2v model...')\n","\n","w2v_lstm = designing_networksssss.model_architecture_word2vec(embedding_matrix_w2v, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n","w2v_lstm, history = designing_networksssss.fit_network(w2v_lstm, X_train, X_test, y_train, y_test, epochs = 15)\n","designing_networksssss.save_network_model(w2v_lstm, modelname = 'w2v_lstm',directory = model_directory)\n","# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'w2v_lstm.json', h5file = 'w2v_lstm.h5')\n","# score = designing_network.analyze_performance(loaded_model, X_test, y_test)\n","# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Step11: designing lstm+w2v model...\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_10 (Embedding)     (None, 150, 100)          1382300   \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 64)                34048     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 1,416,543\n","Trainable params: 34,243\n","Non-trainable params: 1,382,300\n","_________________________________________________________________\n","Train on 11712 samples, validate on 2928 samples\n","Epoch 1/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.4777 - accuracy: 0.7845 - val_loss: 0.3949 - val_accuracy: 0.8271\n","Epoch 2/15\n","11712/11712 [==============================] - 42s 4ms/step - loss: 0.3996 - accuracy: 0.8238 - val_loss: 0.3598 - val_accuracy: 0.8435\n","Epoch 3/15\n","11712/11712 [==============================] - 42s 4ms/step - loss: 0.3729 - accuracy: 0.8369 - val_loss: 0.3453 - val_accuracy: 0.8505\n","Epoch 4/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3585 - accuracy: 0.8463 - val_loss: 0.3387 - val_accuracy: 0.8530\n","Epoch 5/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3456 - accuracy: 0.8501 - val_loss: 0.3314 - val_accuracy: 0.8582\n","Epoch 6/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3408 - accuracy: 0.8535 - val_loss: 0.3253 - val_accuracy: 0.8617\n","Epoch 7/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3332 - accuracy: 0.8549 - val_loss: 0.3257 - val_accuracy: 0.8560\n","Epoch 8/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3240 - accuracy: 0.8599 - val_loss: 0.3244 - val_accuracy: 0.8618\n","Epoch 9/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3215 - accuracy: 0.8641 - val_loss: 0.3147 - val_accuracy: 0.8654\n","Epoch 10/15\n","11712/11712 [==============================] - 42s 4ms/step - loss: 0.3157 - accuracy: 0.8645 - val_loss: 0.3137 - val_accuracy: 0.8646\n","Epoch 11/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3112 - accuracy: 0.8674 - val_loss: 0.3102 - val_accuracy: 0.8674\n","Epoch 12/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3072 - accuracy: 0.8678 - val_loss: 0.3102 - val_accuracy: 0.8689\n","Epoch 13/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.3053 - accuracy: 0.8691 - val_loss: 0.3109 - val_accuracy: 0.8710\n","Epoch 14/15\n","11712/11712 [==============================] - 42s 4ms/step - loss: 0.3021 - accuracy: 0.8712 - val_loss: 0.3086 - val_accuracy: 0.8669\n","Epoch 15/15\n","11712/11712 [==============================] - 43s 4ms/step - loss: 0.2976 - accuracy: 0.8739 - val_loss: 0.3066 - val_accuracy: 0.8718\n","Saved model to disk\n"],"name":"stdout"}]}]}