{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_analysis.ipynb","provenance":[],"authorship_tag":"ABX9TyMx3jGD0WlpTqvg8wSLo+nP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TEEJP49AQ-Qe","colab_type":"code","outputId":"bd02db8e-021a-49ec-9029-7fd58aea5903","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1587235279483,"user_tz":-360,"elapsed":2343145,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":[" # importing libraries\n","\n","import re\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, LSTM, Embedding, Dropout\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from keras import optimizers\n","from keras import regularizers\n","\n","\n","def filter_texts (dataset): # filters texts           \n","    for i in range(0, dataset.shape[0]):\n","        comment = re.sub('[^a-zA-Z0-9\\s@]', ' ', dataset['content'][i])\n","        comment = comment.lower()\n","        comment = comment.split()\n","        comment = [j for j in comment if len(j) > 1]\n","        comment = ' '.join(word for word in comment if not word.startswith('@'))\n","        dataset['content'][i] = comment\n","    return dataset\n","\n","dataset = pd.read_csv('train_data.csv')\n","\n","# analyzing the keywords\n","\n","y = dataset.iloc[:, 0].values\n","\n","keywords = []\n","\n","for i in range (0,30000):\n","    if not(y[i] in keywords):\n","        keywords.append(y[i])\n","\n","\n","for i in range(0,30000):\n","    if (y[i]=='empty' or y[i]=='sadness' or y[i]=='worry' or y[i]=='hate' or y[i]=='anger'):\n","        y[i] = 'negative'\n","        \n","    elif y[i] =='neutral' :\n","        y[i] = 'neutral'\n","        \n","    else:\n","        y[i] = 'positive'\n","        \n","        \n","#filtering the texts\n","\n","dataset = filter_texts(dataset)\n","\n","\n","# visualizing final dataset\n","\n","dataset['sentiment'].value_counts().sort_index().plot.bar()\n","\n","\n","dataset['content'].str.len().plot.hist()\n","\n","#tokenizing\n","    \n","\n","tokenizer = Tokenizer(num_words=5000, split=\" \")\n","tokenizer.fit_on_texts(dataset['content'].values)\n","\n","X = tokenizer.texts_to_sequences(dataset['content'].values)\n","X = pad_sequences(X) # padding our text vector so they all have the same length\n","\n","\n","# Model Designing\n","\n","model = Sequential()\n","model.add(Embedding(5000, 512, input_length=X.shape[1]))\n","model.add(Dropout(0.3))\n","model.add(LSTM(300, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n","model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.2))\n","model.add(Dense(3, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l1(0.01)))\n","\n","\n","adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()\n","\n","# encoding the sentiments\n","y = pd.get_dummies(dataset['sentiment']).values\n","[print(dataset['sentiment'][i], y[i]) for i in range(0,15)]\n","\n","# test train split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","\n","# fitting the model\n","batch_size = 30\n","epochs = 30\n","\n","history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, shuffle = True, validation_data = (X_test,y_test))\n","\n","\n","#visualizing learning process\n","plt.plot(history.history['accuracy'])\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","plt.show()\n","\n","\n","\n","model.save('18thapril220.h5')\n","\n","\n","#prediction\n","\n","predictions = model.predict(X_test)\n","[print(dataset['content'][i], predictions[i], y_test[i]) for i in range(0, 5)]\n","\n","\n","#visualizing results\n","\n","pos_count, neu_count, neg_count = 0, 0, 0\n","real_pos, real_neu, real_neg = 0, 0, 0\n","for i, prediction in enumerate(predictions):\n","    if np.argmax(prediction)==2:\n","        pos_count += 1\n","    elif np.argmax(prediction)==1:\n","        neu_count += 1\n","    else:\n","        neg_count += 1\n","    \n","    if np.argmax(y_test[i])==2:\n","        real_pos += 1\n","    elif np.argmax(y_test[i])==1:    \n","        real_neu += 1\n","    else:\n","        real_neg +=1\n","\n","print('Positive predictions:', pos_count)\n","print('Neutral predictions:', neu_count)\n","print('Negative predictions:', neg_count)\n","print('Real positive:', real_pos)\n","print('Real neutral:', real_neu)\n","print('Real negative:', real_neg)\n","\n","\n","\n","# testing using self made comments\n","cmnt = [\"@sakibchowdhury : you are bullshit \", \n","        \"there is no God\",\n","        \"i'm really sad\",\n","        \"your service is good\", \n","        \"life is beautiful\",\n","        \"i really hate you sakib\",\n","        \"go to hell\",\n","        \"God sees us\",\n","        \"we should love everyone\",       \n","        \"you are a dog\"]\n","\n","for i in range(0, len(cmnt)):\n","        comment = re.sub('[^a-zA-Z0-9\\s@]', ' ', cmnt[i])\n","\n","        comment = comment.lower()\n","        comment = comment.split()\n","\n","        comment = [j for j in comment if len(j) > 1]\n","\n","        comment = ' '.join(word for word in comment if not word.startswith('@'))\n","        cmnt[i] = comment\n","\n","X_samp = tokenizer.texts_to_sequences(cmnt)\n","X_samp = pad_sequences(X_samp,31)\n","model.predict(X_samp)\n","# -*- coding: utf-8 -*-\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 31, 512)           2560000   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 31, 512)           0         \n","_________________________________________________________________\n","lstm_7 (LSTM)                (None, 31, 300)           975600    \n","_________________________________________________________________\n","lstm_8 (LSTM)                (None, 300)               721200    \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 903       \n","=================================================================\n","Total params: 4,257,703\n","Trainable params: 4,257,703\n","Non-trainable params: 0\n","_________________________________________________________________\n","negative [1 0 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","positive [0 0 1]\n","neutral [0 1 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","neutral [0 1 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","negative [1 0 0]\n","positive [0 0 1]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 24000 samples, validate on 6000 samples\n","Epoch 1/30\n","24000/24000 [==============================] - 116s 5ms/step - loss: 1.0002 - accuracy: 0.5439 - val_loss: 0.9326 - val_accuracy: 0.5832\n","Epoch 2/30\n","24000/24000 [==============================] - 117s 5ms/step - loss: 0.8789 - accuracy: 0.6211 - val_loss: 0.9194 - val_accuracy: 0.5985\n","Epoch 3/30\n","24000/24000 [==============================] - 114s 5ms/step - loss: 0.8233 - accuracy: 0.6530 - val_loss: 0.9492 - val_accuracy: 0.5913\n","Epoch 4/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.7626 - accuracy: 0.6877 - val_loss: 0.9865 - val_accuracy: 0.5805\n","Epoch 5/30\n","24000/24000 [==============================] - 112s 5ms/step - loss: 0.7004 - accuracy: 0.7180 - val_loss: 1.0468 - val_accuracy: 0.5810\n","Epoch 6/30\n","24000/24000 [==============================] - 112s 5ms/step - loss: 0.6373 - accuracy: 0.7486 - val_loss: 1.1080 - val_accuracy: 0.5568\n","Epoch 7/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.5753 - accuracy: 0.7823 - val_loss: 1.2090 - val_accuracy: 0.5495\n","Epoch 8/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.5202 - accuracy: 0.8056 - val_loss: 1.2405 - val_accuracy: 0.5398\n","Epoch 9/30\n","24000/24000 [==============================] - 112s 5ms/step - loss: 0.4712 - accuracy: 0.8261 - val_loss: 1.3687 - val_accuracy: 0.5508\n","Epoch 10/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.4235 - accuracy: 0.8484 - val_loss: 1.3987 - val_accuracy: 0.5440\n","Epoch 11/30\n","24000/24000 [==============================] - 114s 5ms/step - loss: 0.3904 - accuracy: 0.8630 - val_loss: 1.4533 - val_accuracy: 0.5383\n","Epoch 12/30\n","24000/24000 [==============================] - 117s 5ms/step - loss: 0.3587 - accuracy: 0.8758 - val_loss: 1.5351 - val_accuracy: 0.5338\n","Epoch 13/30\n","24000/24000 [==============================] - 115s 5ms/step - loss: 0.3310 - accuracy: 0.8870 - val_loss: 1.6176 - val_accuracy: 0.5372\n","Epoch 14/30\n","24000/24000 [==============================] - 114s 5ms/step - loss: 0.3035 - accuracy: 0.8972 - val_loss: 1.6573 - val_accuracy: 0.5368\n","Epoch 15/30\n","24000/24000 [==============================] - 114s 5ms/step - loss: 0.2842 - accuracy: 0.9075 - val_loss: 1.6990 - val_accuracy: 0.5112\n","Epoch 16/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.2621 - accuracy: 0.9160 - val_loss: 1.7451 - val_accuracy: 0.5227\n","Epoch 17/30\n","24000/24000 [==============================] - 114s 5ms/step - loss: 0.2488 - accuracy: 0.9212 - val_loss: 1.7605 - val_accuracy: 0.5322\n","Epoch 18/30\n","24000/24000 [==============================] - 115s 5ms/step - loss: 0.2332 - accuracy: 0.9270 - val_loss: 1.8192 - val_accuracy: 0.5295\n","Epoch 19/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.2216 - accuracy: 0.9317 - val_loss: 1.8234 - val_accuracy: 0.5177\n","Epoch 20/30\n","24000/24000 [==============================] - 113s 5ms/step - loss: 0.2034 - accuracy: 0.9395 - val_loss: 1.9499 - val_accuracy: 0.5270\n","Epoch 21/30\n","11910/24000 [=============>................] - ETA: 55s - loss: 0.1926 - accuracy: 0.9452"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-b75089aef92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}