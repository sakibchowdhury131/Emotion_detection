{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bidirectional_lstm+glove.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM7AX8/b5mQIT4cJQAaVUz3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1NyprGW-Jdm3","colab_type":"code","outputId":"9185c2ef-3082-4be7-ef11-81eb9bf18060","executionInfo":{"status":"error","timestamp":1589360048623,"user_tz":-360,"elapsed":445099,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}},"colab":{"base_uri":"https://localhost:8080/","height":469}},"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sat May  9 22:34:44 2020\n","\n","@author: sakib\n","\n","\"\"\"\n","\n","\n","#change base directory\n","import os\n","\n","base_path=r'/content'\n","working_directory = '/content'\n","data_folder = r'/content/data'\n","embedding_folder = r'/content/embeddings'\n","models_folder = r'/content/models'\n","model_directory = working_directory+'/'+'models'\n","\n","\n","def change_base_dir(base_dir_path):\n","    \"\"\" Change the working directopry of the code\"\"\"\n","    \n","    if not os.path.exists(base_dir_path):\n","        print ('creating directory', base_dir_path)\n","        os.makedirs(base_dir_path)\n","    print ('Changing base directory to ', base_dir_path)\n","    os.chdir(base_dir_path)\n"," \n","      \n","\n","# base_folder='data'\n","# base_dir_path=base_path+'/'+base_folder\n","# change_base_dir(base_dir_path)\n","# download_data.extract_file('/media/sakib/alpha/work/EmotionDetectionDir/git/data/glove.6B.zip')\n","\n","\n","\n","change_base_dir(base_path)\n","if not os.path.exists(data_folder):\n","        os.makedirs(data_folder)\n","if not os.path.exists(embedding_folder):\n","        os.makedirs(embedding_folder)\n","if not os.path.exists(models_folder):\n","        os.makedirs(models_folder)\n","  \n","#loading necessary files\n","from load_preprocess import load_data,load_data_embedding\n","from load_preprocess import preprocess_data\n","from load_preprocess import read_labels\n","import word2vec\n","import sswe\n","import glove_file\n","import designing_network\n","import download_data\n","\n","\n","#importing libraries\n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","\n","\n","\n","# Download data\n","\n","print('Checking requirements:')\n","download_data.download_data(base_path = base_path)\n","\n","\n","EMBEDDING_DIM = 100\n","\n","\n","\n","# loading twitter_dataset_small\n","print('Step6: Loading Twitter Dataset')\n","dataset = load_data(working_directory+'/'+'data'+'/'+'Tweets.csv')\n","texts = preprocess_data(dataset)\n","y = pd.get_dummies(dataset['Label']).values\n","\n","\n","\n","#tokenizing\n","print ('Step7: Tokenizing...')\n","\n","tokens = []\n","for line in texts:\n","    words = word_tokenize(line)\n","    tokens.append(words)\n","\n","\n","\n","tokenizer_obj = Tokenizer()\n","tokenizer_obj.fit_on_texts(tokens)\n","sequences = tokenizer_obj.texts_to_sequences(tokens)\n","\n","\n","#padding\n","print ('Step8: Padding...')\n","tokenizer_word_index = tokenizer_obj.word_index\n","max_length = 150\n","review_pad = pad_sequences(sequences, maxlen = max_length)\n","\n","num_words = len(tokenizer_word_index) + 1\n","\n","# train test split\n","print('Step9: train and test set generation...')\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(review_pad, y, test_size = 0.20, random_state = 0)\n","\n","# glove embedding matrix\n","print ('Step 14: Generating glove embedding matrix...')\n","embedding_matrix_glove = glove_file.load_glove(working_directory+'/'+'data'+'/'+'glove.6B.100d.txt', tokenizer_word_index=tokenizer_word_index, EMBEDDING_DIM=EMBEDDING_DIM)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Changing base directory to  /content\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Checking requirements:\n","Downloading stanford data\n","Extracting stanford data\n","Downloading Twitter data\n","Downloading glove model...\n","Extracting glove data\n","Step6: Loading Twitter Dataset\n","Step7: Tokenizing...\n","Step8: Padding...\n","Step9: train and test set generation...\n","Step 14: Generating glove embedding matrix...\n","Step15: designing lstm+w2v model...\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ed0c73e97a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# training the glove model with lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step15: designing lstm+w2v model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mglove_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_architecture_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mglove_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mdesigning_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_network_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove_lstm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_words' is not defined"]}]},{"cell_type":"code","metadata":{"id":"PbRGHDpB-uaR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":299},"outputId":"c9544f9a-efd7-4c29-b2f6-c6d1bd605bae","executionInfo":{"status":"error","timestamp":1590748197917,"user_tz":-360,"elapsed":1052,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}}},"source":["import tools\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c94ac9b044f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tools'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"OHFwh7X7P0BZ","colab_type":"code","outputId":"9255cde2-2dea-4e13-ee49-d4bd033b56dc","executionInfo":{"status":"ok","timestamp":1589360658472,"user_tz":-360,"elapsed":451091,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["import designing_networks\n","\n","num_words = len(tokenizer_word_index) + 1\n","# training the glove model with lstm\n","print('Step15: designing lstm+w2v model...')\n","glove_lstm = designing_networks.model_architecture_glove(embedding_matrix_glove, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n","glove_lstm, history = designing_networks.fit_network(glove_lstm, X_train, X_test, y_train, y_test)\n","designing_networks.save_network_model(glove_lstm, modelname = 'glove_lstm',directory = model_directory)\n","# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'glove_lstm.json', h5file = 'glove_lstm.h5')\n","# score = designing_network.analyze_performance(loaded_model, X_test, y_test)\n","# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Step15: designing lstm+w2v model...\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 150, 100)          1382300   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 64)                34048     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 1,416,543\n","Trainable params: 34,243\n","Non-trainable params: 1,382,300\n","_________________________________________________________________\n","Train on 11712 samples, validate on 2928 samples\n","Epoch 1/10\n","11712/11712 [==============================] - 46s 4ms/step - loss: 0.4912 - accuracy: 0.7775 - val_loss: 0.4228 - val_accuracy: 0.8122\n","Epoch 2/10\n","11712/11712 [==============================] - 44s 4ms/step - loss: 0.4086 - accuracy: 0.8205 - val_loss: 0.3708 - val_accuracy: 0.8385\n","Epoch 3/10\n","11712/11712 [==============================] - 44s 4ms/step - loss: 0.3802 - accuracy: 0.8321 - val_loss: 0.3515 - val_accuracy: 0.8495\n","Epoch 4/10\n","11712/11712 [==============================] - 44s 4ms/step - loss: 0.3639 - accuracy: 0.8429 - val_loss: 0.3480 - val_accuracy: 0.8517\n","Epoch 5/10\n","11712/11712 [==============================] - 44s 4ms/step - loss: 0.3501 - accuracy: 0.8495 - val_loss: 0.3419 - val_accuracy: 0.8551\n","Epoch 6/10\n","11712/11712 [==============================] - 45s 4ms/step - loss: 0.3415 - accuracy: 0.8519 - val_loss: 0.3310 - val_accuracy: 0.8612\n","Epoch 7/10\n","11712/11712 [==============================] - 45s 4ms/step - loss: 0.3358 - accuracy: 0.8544 - val_loss: 0.3317 - val_accuracy: 0.8586\n","Epoch 8/10\n","11712/11712 [==============================] - 45s 4ms/step - loss: 0.3275 - accuracy: 0.8577 - val_loss: 0.3273 - val_accuracy: 0.8633\n","Epoch 9/10\n","11712/11712 [==============================] - 45s 4ms/step - loss: 0.3184 - accuracy: 0.8642 - val_loss: 0.3257 - val_accuracy: 0.8591\n","Epoch 10/10\n","11712/11712 [==============================] - 45s 4ms/step - loss: 0.3154 - accuracy: 0.8658 - val_loss: 0.3213 - val_accuracy: 0.8637\n","Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-pAgW4M5NpKZ","colab_type":"code","outputId":"2c50d472-9427-47d1-d334-b2b31b1b92b1","executionInfo":{"status":"ok","timestamp":1589359593056,"user_tz":-360,"elapsed":7661,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["pip install num2words"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting num2words\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n","\r\u001b[K     |███▎                            | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n","Installing collected packages: num2words\n","Successfully installed num2words-0.5.10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hVZoaXqjNq9N","colab_type":"code","outputId":"5297bcfe-2d38-44af-aa1c-e36919e7f953","executionInfo":{"status":"ok","timestamp":1589359601389,"user_tz":-360,"elapsed":2723,"user":{"displayName":"sakib chowdhury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMtAh0tpeZrt3Q9qj5HQ7xGfGKHp3ixCOMDofQvQ=s64","userId":"01322476370589686234"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]}]}