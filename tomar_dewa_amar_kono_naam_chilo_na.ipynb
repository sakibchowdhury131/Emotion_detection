{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tomar_dewa_amar_kono_naam_chilo_na.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-UJfjVbZRIh1jDT9TlML7WKP9XD19bPU",
      "authorship_tag": "ABX9TyNg7W9cfGmjhmi6lmV51sG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibchowdhury131/Emotion_detection/blob/master/tomar_dewa_amar_kono_naam_chilo_na.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lKe_-wBCf9Q",
        "colab_type": "code",
        "outputId": "9a25763a-88f3-48cc-fa1e-efd22981563d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install num2words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.6/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj1Yd51sC32H",
        "colab_type": "code",
        "outputId": "7b956775-4ff5-4b5e-8cfb-6214009ee211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt1_6iPaC-ED",
        "colab_type": "code",
        "outputId": "57dc8354-174a-43cd-adf5-17f54112a883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat May  9 22:34:44 2020\n",
        "\n",
        "@author: sakib\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#change base directory\n",
        "import os\n",
        "\n",
        "base_path=r'/content/drive/My Drive/Sentiment_analysis_NLP/All_codes'\n",
        "working_directory = '/content/drive/My Drive/Sentiment_analysis_NLP/All_codes'\n",
        "data_folder = r'/content/drive/My Drive/Sentiment_analysis_NLP/All_codes/data'\n",
        "embedding_folder = r'/content/drive/My Drive/Sentiment_analysis_NLP/All_codes/embeddings'\n",
        "models_folder = r'/content/drive/My Drive/Sentiment_analysis_NLP/All_codes/models'\n",
        "model_directory = working_directory+'/'+'models'\n",
        "\n",
        "\n",
        "def change_base_dir(base_dir_path):\n",
        "    \"\"\" Change the working directopry of the code\"\"\"\n",
        "    \n",
        "    if not os.path.exists(base_dir_path):\n",
        "        print ('creating directory', base_dir_path)\n",
        "        os.makedirs(base_dir_path)\n",
        "    print ('Changing base directory to ', base_dir_path)\n",
        "    os.chdir(base_dir_path)\n",
        " \n",
        "      \n",
        "\n",
        "# base_folder='data'\n",
        "# base_dir_path=base_path+'/'+base_folder\n",
        "# change_base_dir(base_dir_path)\n",
        "# download_data.extract_file('/media/sakib/alpha/work/EmotionDetectionDir/git/data/glove.6B.zip')\n",
        "\n",
        "\n",
        "\n",
        "change_base_dir(base_path)\n",
        "if not os.path.exists(data_folder):\n",
        "        os.makedirs(data_folder)\n",
        "if not os.path.exists(embedding_folder):\n",
        "        os.makedirs(embedding_folder)\n",
        "if not os.path.exists(models_folder):\n",
        "        os.makedirs(models_folder)\n",
        "  \n",
        "#loading necessary files\n",
        "from load_preprocess import load_data_embedding\n",
        "from load_preprocess import preprocess_data\n",
        "from load_preprocess import read_labels\n",
        "import word2vec\n",
        "import sswe\n",
        "import glove_file\n",
        "import designing_network\n",
        "import download_data\n",
        "\n",
        "\n",
        "#importing libraries\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Download data\n",
        "\n",
        "print('Checking requirements:')\n",
        "download_data.download_data(base_path = base_path)\n",
        "\n",
        "#loading data\n",
        "print('Step1: Loading Embedding training Dataset...')\n",
        "\n",
        "\n",
        "dataset_embedding = load_data_embedding(working_directory+'/data/'+'training.1600000.processed.noemoticon.csv')\n",
        "print('Step2: Shuffling data...')\n",
        "dataset_embedding = dataset_embedding.sample(frac=1) # reshuffling the data\n",
        "print('Step3: Preprocessing the texts...')\n",
        "texts = preprocess_data(dataset_embedding)\n",
        "labels = read_labels(dataset_embedding)\n",
        "\n",
        "\n",
        "# building word2vec model\n",
        "print('Step4: Building word2vec model...')\n",
        "EMBEDDING_DIM = 100\n",
        "w2v = word2vec.create_word2vec(directory = working_directory+'/'+'embeddings',texts = texts ,min_count = 1,EMBEDDING_DIM = EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "\n",
        "#building sswe model\n",
        "print('Step5: Building sswe model...')\n",
        "sswe_model,training_word_index = sswe.sswe_model(texts, labels)\n",
        "embedding_weights, word_indices_df, merged = sswe.save_sswe(sswe_model,training_word_index,directory = working_directory+'/'+'embeddings')\n",
        "print('Embedding Layers are trained.')\n",
        "\n",
        "\n",
        "#loading sentiment treebank dataset\n",
        "print ('Step6: loading sentiment treebank dataset...')\n",
        "dataset = pd.read_csv('stanford_sentiment_treebank_half_processed.csv')\n",
        "texts = dataset['Text']\n",
        "y = dataset.iloc[:,2:5].values\n",
        "\n",
        "\n",
        "#tokenizing\n",
        "print ('Step7: Tokenizing...')\n",
        "\n",
        "tokens = []\n",
        "for line in texts:\n",
        "    words = word_tokenize(line)\n",
        "    tokens.append(words)\n",
        "\n",
        "\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(tokens)\n",
        "sequences = tokenizer_obj.texts_to_sequences(tokens)\n",
        "\n",
        "\n",
        "#padding\n",
        "print ('Step8: Padding...')\n",
        "tokenizer_word_index = tokenizer_obj.word_index\n",
        "max_length = 150\n",
        "review_pad = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "\n",
        "\n",
        "# train test split\n",
        "print('Step9: train and test set generation...')\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(review_pad, y, test_size = 0.20, random_state = 0)\n",
        "\n",
        "\n",
        "# word2vec Embedding Matrix\n",
        "print('Step10: Generating word2vec embedding matrix...')\n",
        "num_words = len(tokenizer_word_index) + 1\n",
        "embedding_matrix_w2v = word2vec.load_word2vec(working_directory+'/'+'embeddings'+'/'+'embeddings_w2v.txt', tokenizer_word_index=tokenizer_word_index, EMBEDDING_DIM=EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "# training the word2vec model with lstm\n",
        "print('Step11: designing lstm+w2v model...')\n",
        "\n",
        "w2v_lstm = designing_network.model_architecture_word2vec_lstm(embedding_matrix_w2v, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "w2v_lstm, history = designing_network.fit_network(w2v_lstm, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(w2v_lstm, modelname = 'w2v_lstm',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'w2v_lstm.json', h5file = 'w2v_lstm.h5')\n",
        "# designing_network.analyze_performance(model_name = 'w2v+lstm', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "# training the word2vec model with gru\n",
        "print('Step12: designing gru+w2v model...')\n",
        "\n",
        "w2v_gru = designing_network.model_architecture_word2vec_gru(embedding_matrix_w2v, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "w2v_gru, history = designing_network.fit_network(w2v_gru, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(w2v_gru, modelname = 'w2v_gru', directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'w2v_gru.json', h5file = 'w2v_gru.h5')\n",
        "# designing_network.analyze_performance(model_name = 'w2v+gru', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "# training the word2vec model with bidirectional\n",
        "print('Step13: designing bidirectional+w2v model...')\n",
        "\n",
        "w2v_bidirectional = designing_network.model_architecture_word2vec_bidirectional(embedding_matrix_w2v, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "w2v_bidirectional,history = designing_network.fit_network(w2v_bidirectional, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(w2v_bidirectional, modelname = 'w2v_bidirectional',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'w2v_bidirectional.json', h5file = 'w2v_bidirectional.h5')\n",
        "# designing_network.analyze_performance(model_name = 'w2v+bidirectional', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# sswe embedding matrix\n",
        "print('Step14: Generating sswe embedding matrix...')\n",
        "sswe_embedding_filename = working_directory+'/'+'embeddings'+'/'+'embeddings_sswe.tsv'\n",
        "embedding_matrix_sswe = sswe.load_sswe(filename = sswe_embedding_filename, tokenizer_word_index = tokenizer_word_index, EMBEDDING_DIM = 50)\n",
        "\n",
        "    \n",
        "# training the sswe model with lstm\n",
        "print('Step15: designing lstm+sswe model...')\n",
        "sswe_lstm = designing_network.model_architecture_sswe_lstm(embedding_matrix_sswe, num_words,EMBEDDING_DIM = 50 , max_length = max_length)\n",
        "sswe_lstm, history = designing_network.fit_network(sswe_lstm, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(sswe_lstm, modelname = 'sswe_lstm',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'sswe_bidirectional.json', h5file = 'sswe_bidirectional.h5')\n",
        "# designing_network.analyze_performance(model_name = 'sswe+bidirectional', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "    \n",
        "# training the sswe model with gru\n",
        "print('Step16: designing gru+sswe model...')\n",
        "sswe_gru = designing_network.model_architecture_sswe_gru(embedding_matrix_sswe, num_words,EMBEDDING_DIM = 50 , max_length = max_length)\n",
        "sswe_gru, history = designing_network.fit_network(sswe_gru, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(sswe_gru, modelname = 'sswe_gru',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'sswe_gru.json', h5file = 'sswe_gru.h5')\n",
        "# designing_network.analyze_performance(model_name = 'sswe+gru', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "# training the sswe model with bidirectional\n",
        "print('Step17: designing bidirectional+sswe model...')\n",
        "sswe_bidirectional = designing_network.model_architecture_sswe_bidirectional(embedding_matrix_sswe, num_words,EMBEDDING_DIM = 50 , max_length = max_length)\n",
        "sswe_bidirectional, history = designing_network.fit_network(sswe_bidirectional, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(sswe_bidirectional, modelname = 'sswe_bidirectional',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'sswe_bidirectional.json', h5file = 'sswe_bidirectional.h5')\n",
        "# designing_network.analyze_performance(model_name = 'sswe+bidirectional', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "# glove embedding matrix\n",
        "print ('Step18: Generating glove embedding matrix...')\n",
        "embedding_matrix_glove = glove_file.load_glove(working_directory+'/'+'data'+'/'+'glove.6B.100d.txt', tokenizer_word_index=tokenizer_word_index, EMBEDDING_DIM=EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "\n",
        "# training the glove model with lstm\n",
        "print('Step19: designing lstm+glove model...')\n",
        "glove_lstm = designing_network.model_architecture_glove_lstm(embedding_matrix_glove, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "glove_lstm, history = designing_network.fit_network(glove_lstm, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(glove_lstm, modelname = 'glove_lstm',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'glove_lstm.json', h5file = 'glove_lstm.h5')\n",
        "# designing_network.analyze_performance(model_name = 'glove+lstm', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "# training the glove model with gru\n",
        "print('Step20: designing gru+glove model...')\n",
        "glove_gru = designing_network.model_architecture_glove_gru(embedding_matrix_glove, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "glove_gru, history = designing_network.fit_network(glove_gru, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(glove_gru, modelname = 'glove_gru',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'glove_gru.json', h5file = 'glove_gru.h5')\n",
        "# designing_network.analyze_performance(model_name = 'glove+gru', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training the glove model with bidirectional\n",
        "print('Step21: designing bidirectional+glove model...')\n",
        "glove_bidirectional = designing_network.model_architecture_glove_bidirectional(embedding_matrix_glove, num_words,EMBEDDING_DIM = EMBEDDING_DIM , max_length = max_length)\n",
        "glove_bidirectional, history = designing_network.fit_network(glove_bidirectional, X_train, X_test, y_train, y_test,batch_size = 512)\n",
        "designing_network.save_network_model(glove_bidirectional, modelname = 'glove_bidirectional',directory = model_directory)\n",
        "# loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'glove_bidirectional.json', h5file = 'glove_bidirectional.h5')\n",
        "# designing_network.analyze_performance(model_name = 'glove+bidirectional', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training the parallel network\n",
        "print ('Step16: Training parallel network...')\n",
        "embedding_matrix_glove = glove_file.load_glove(working_directory+'/'+'data'+'/'+'glove.6B.100d.txt', tokenizer_word_index=tokenizer_word_index, EMBEDDING_DIM=100)\n",
        "print('glove matrix created')\n",
        "sswe_embedding_filename = working_directory+'/'+'embeddings'+'/'+'embeddings_sswe.tsv'\n",
        "embedding_matrix_sswe = sswe.load_sswe(filename = sswe_embedding_filename, tokenizer_word_index = tokenizer_word_index, EMBEDDING_DIM = 50)\n",
        "print('sswe matrix created')\n",
        "model = designing_network.parallel_network(embedding_matrix_L = embedding_matrix_glove,\n",
        "                                           embedding_matrix_R = embedding_matrix_sswe, \n",
        "                                           num_words = num_words,\n",
        "                                           EMBEDDING_DIM_L = 100,\n",
        "                                           EMBEDDING_DIM_R = 50,\n",
        "                                           max_length = max_length)\n",
        "print ('model generated')\n",
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
        "model.summary()\n",
        "\n",
        "lstm_glove_lstm_sswe, history = designing_network.fit_network_parallel(model = model, \n",
        "                                                              X_train = X_train, \n",
        "                                                              X_test = X_test, \n",
        "                                                              y_train = y_train, \n",
        "                                                              y_test = y_test,\n",
        "                                                              batch_size = 512)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "designing_network.save_network_model(lstm_glove_lstm_sswe, modelname = 'lstm_glove_lstm_sswe',directory = model_directory)\n",
        "loaded_model = designing_network.load_network_model( directory = working_directory+'/'+'models', jsonfile = 'lstm_glove_lstm_sswe.json', h5file = 'lstm_glove_lstm_sswe.h5')\n",
        "designing_network.analyze_performance_parallel(model_name = 'lstm_glove_lstm_sswe', loaded_model = loaded_model,X_test = X_test,y_test = y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Changing base directory to  /content/drive/My Drive/Sentiment_analysis_NLP/All_codes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Checking requirements:\n",
            "Downloading stanford data\n",
            "Extracting stanford data\n",
            "Downloading Twitter data\n",
            "Downloading glove model...\n",
            "Extracting glove data\n",
            "Step1: Loading Embedding training Dataset...\n",
            "Step2: Shuffling data...\n",
            "Step3: Preprocessing the texts...\n",
            "Step4: Building word2vec model...\n",
            "Saving word2vec model in the disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step5: Building sswe model...\n",
            "1600000 1600000\n",
            "Using Keras tokenizer to tokenize and build word index\n",
            "Size of the vocab is 352268\n",
            "Padding sentences and shuffling the sswe train data\n",
            "Initializing the model\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 15, 50)            17613500  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 15)            3765      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1, 15)             0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 32        \n",
            "=================================================================\n",
            "Total params: 17,617,537\n",
            "Trainable params: 17,617,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Sentiment_analysis_NLP/All_codes/sswe.py:129: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  model.fit(train_x, train_y,nb_epoch=no_epochs, batch_size=batch_size,validation_data=(valid_x, valid_y),callbacks=[mcp])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1280000 samples, validate on 320000 samples\n",
            "Epoch 1/5\n",
            "1280000/1280000 [==============================] - 10s 8us/step - loss: 0.5133 - acc: 0.7520 - val_loss: 0.4898 - val_acc: 0.7646\n",
            "Epoch 2/5\n",
            "1280000/1280000 [==============================] - 3s 3us/step - loss: 0.4778 - acc: 0.7732 - val_loss: 0.5030 - val_acc: 0.7642\n",
            "Epoch 3/5\n",
            "1280000/1280000 [==============================] - 3s 2us/step - loss: 0.4986 - acc: 0.7629 - val_loss: 0.5248 - val_acc: 0.7493\n",
            "Epoch 4/5\n",
            "1280000/1280000 [==============================] - 3s 3us/step - loss: 0.5115 - acc: 0.7550 - val_loss: 0.5493 - val_acc: 0.7244\n",
            "Epoch 5/5\n",
            "1280000/1280000 [==============================] - 3s 3us/step - loss: 0.5412 - acc: 0.7320 - val_loss: 0.5455 - val_acc: 0.7354\n",
            "(352268, 2) (352270, 51)\n",
            "(352268, 52)\n",
            "Embedding Layers are trained.\n",
            "Step6: loading sentiment treebank dataset...\n",
            "Step7: Tokenizing...\n",
            "Step8: Padding...\n",
            "Step9: train and test set generation...\n",
            "Step10: Generating word2vec embedding matrix...\n",
            "Step11: designing lstm+w2v model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 150, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 1,953,703\n",
            "Trainable params: 161,103\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 199s 1ms/step - loss: 0.5760 - accuracy: 0.7000 - val_loss: 0.5357 - val_accuracy: 0.7336\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 198s 1ms/step - loss: 0.5468 - accuracy: 0.7248 - val_loss: 0.5211 - val_accuracy: 0.7445\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5345 - accuracy: 0.7350 - val_loss: 0.5119 - val_accuracy: 0.7510\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5267 - accuracy: 0.7402 - val_loss: 0.5049 - val_accuracy: 0.7569\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 198s 1ms/step - loss: 0.5212 - accuracy: 0.7442 - val_loss: 0.4989 - val_accuracy: 0.7601\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5160 - accuracy: 0.7478 - val_loss: 0.4920 - val_accuracy: 0.7652\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.5121 - accuracy: 0.7502 - val_loss: 0.4889 - val_accuracy: 0.7673\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.5076 - accuracy: 0.7527 - val_loss: 0.4826 - val_accuracy: 0.7709\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 195s 1ms/step - loss: 0.5036 - accuracy: 0.7562 - val_loss: 0.4788 - val_accuracy: 0.7725\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 195s 1ms/step - loss: 0.4998 - accuracy: 0.7585 - val_loss: 0.4748 - val_accuracy: 0.7756\n",
            "Saved model to disk\n",
            "Step12: designing gru+w2v model...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 32)                12768     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,805,467\n",
            "Trainable params: 12,867\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 116s 608us/step - loss: 0.5861 - accuracy: 0.6939 - val_loss: 0.5684 - val_accuracy: 0.7117\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 116s 607us/step - loss: 0.5594 - accuracy: 0.7170 - val_loss: 0.5612 - val_accuracy: 0.7170\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 116s 608us/step - loss: 0.5513 - accuracy: 0.7233 - val_loss: 0.5552 - val_accuracy: 0.7205\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 117s 609us/step - loss: 0.5465 - accuracy: 0.7273 - val_loss: 0.5525 - val_accuracy: 0.7244\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 116s 605us/step - loss: 0.5428 - accuracy: 0.7297 - val_loss: 0.5478 - val_accuracy: 0.7248\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 115s 602us/step - loss: 0.5410 - accuracy: 0.7318 - val_loss: 0.5455 - val_accuracy: 0.7265\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 116s 607us/step - loss: 0.5359 - accuracy: 0.7349 - val_loss: 0.5426 - val_accuracy: 0.7280\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 114s 598us/step - loss: 0.5336 - accuracy: 0.7370 - val_loss: 0.5405 - val_accuracy: 0.7299\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 112s 587us/step - loss: 0.5304 - accuracy: 0.7393 - val_loss: 0.5390 - val_accuracy: 0.7308\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 114s 594us/step - loss: 0.5301 - accuracy: 0.7394 - val_loss: 0.5379 - val_accuracy: 0.7313\n",
            "Saved model to disk\n",
            "Step13: designing bidirectional+w2v model...\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               84480     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,877,467\n",
            "Trainable params: 84,867\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 169s 884us/step - loss: 0.5545 - accuracy: 0.7200 - val_loss: 0.5284 - val_accuracy: 0.7393\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 167s 872us/step - loss: 0.5217 - accuracy: 0.7452 - val_loss: 0.5162 - val_accuracy: 0.7486\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 166s 870us/step - loss: 0.5097 - accuracy: 0.7539 - val_loss: 0.5058 - val_accuracy: 0.7563\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 166s 870us/step - loss: 0.5007 - accuracy: 0.7595 - val_loss: 0.4985 - val_accuracy: 0.7610\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 165s 860us/step - loss: 0.4931 - accuracy: 0.7641 - val_loss: 0.4919 - val_accuracy: 0.7639\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 166s 868us/step - loss: 0.4859 - accuracy: 0.7692 - val_loss: 0.4859 - val_accuracy: 0.7689\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 166s 866us/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4827 - val_accuracy: 0.7698\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 167s 872us/step - loss: 0.4736 - accuracy: 0.7765 - val_loss: 0.4795 - val_accuracy: 0.7726\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 167s 873us/step - loss: 0.4682 - accuracy: 0.7798 - val_loss: 0.4757 - val_accuracy: 0.7749\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 168s 876us/step - loss: 0.4631 - accuracy: 0.7831 - val_loss: 0.4704 - val_accuracy: 0.7786\n",
            "Saved model to disk\n",
            "Step14: Generating sswe embedding matrix...\n",
            "Step15: designing lstm+sswe model...\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 150, 50)           896300    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 150, 100)          60400     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 1,037,403\n",
            "Trainable params: 141,103\n",
            "Non-trainable params: 896,300\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 199s 1ms/step - loss: 0.5836 - accuracy: 0.6932 - val_loss: 0.5610 - val_accuracy: 0.7117\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 198s 1ms/step - loss: 0.5624 - accuracy: 0.7118 - val_loss: 0.5464 - val_accuracy: 0.7231\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 202s 1ms/step - loss: 0.5536 - accuracy: 0.7193 - val_loss: 0.5345 - val_accuracy: 0.7320\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 202s 1ms/step - loss: 0.5471 - accuracy: 0.7240 - val_loss: 0.5276 - val_accuracy: 0.7377\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 201s 1ms/step - loss: 0.5422 - accuracy: 0.7275 - val_loss: 0.5236 - val_accuracy: 0.7405\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 198s 1ms/step - loss: 0.5388 - accuracy: 0.7302 - val_loss: 0.5204 - val_accuracy: 0.7437\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5353 - accuracy: 0.7325 - val_loss: 0.5152 - val_accuracy: 0.7467\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5328 - accuracy: 0.7345 - val_loss: 0.5116 - val_accuracy: 0.7485\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.5294 - accuracy: 0.7362 - val_loss: 0.5078 - val_accuracy: 0.7512\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.5276 - accuracy: 0.7378 - val_loss: 0.5083 - val_accuracy: 0.7511\n",
            "Saved model to disk\n",
            "Step16: designing gru+sswe model...\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 150, 50)           896300    \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 32)                7968      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 904,367\n",
            "Trainable params: 8,067\n",
            "Non-trainable params: 896,300\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 118s 614us/step - loss: 0.6254 - accuracy: 0.6605 - val_loss: 0.6037 - val_accuracy: 0.6797\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 116s 606us/step - loss: 3.6314 - accuracy: 0.6810 - val_loss: 0.6023 - val_accuracy: 0.6818\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 115s 603us/step - loss: 0.6140 - accuracy: 0.6842 - val_loss: 0.5972 - val_accuracy: 0.6839\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 117s 612us/step - loss: 0.5920 - accuracy: 0.6865 - val_loss: 0.5942 - val_accuracy: 0.6854\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 116s 609us/step - loss: 0.6212 - accuracy: 0.6846 - val_loss: 0.5967 - val_accuracy: 0.6837\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 116s 604us/step - loss: 4.4088 - accuracy: 0.6829 - val_loss: 0.5985 - val_accuracy: 0.6825\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 115s 603us/step - loss: 0.5961 - accuracy: 0.6844 - val_loss: 0.5958 - val_accuracy: 0.6833\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 115s 603us/step - loss: 0.5918 - accuracy: 0.6860 - val_loss: 0.5939 - val_accuracy: 0.6853\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 115s 602us/step - loss: 0.5910 - accuracy: 0.6872 - val_loss: 0.5926 - val_accuracy: 0.6862\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 115s 600us/step - loss: 0.5898 - accuracy: 0.6879 - val_loss: 0.5916 - val_accuracy: 0.6871\n",
            "Saved model to disk\n",
            "Step17: designing bidirectional+sswe model...\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 150, 50)           896300    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               58880     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 955,567\n",
            "Trainable params: 59,267\n",
            "Non-trainable params: 896,300\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 167s 875us/step - loss: 0.5750 - accuracy: 0.7010 - val_loss: 0.5508 - val_accuracy: 0.7214\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 166s 868us/step - loss: 0.5390 - accuracy: 0.7306 - val_loss: 0.5327 - val_accuracy: 0.7351\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 167s 870us/step - loss: 0.5223 - accuracy: 0.7431 - val_loss: 0.5221 - val_accuracy: 0.7427\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 166s 869us/step - loss: 0.5103 - accuracy: 0.7515 - val_loss: 0.5131 - val_accuracy: 0.7486\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 167s 870us/step - loss: 0.5007 - accuracy: 0.7575 - val_loss: 0.5062 - val_accuracy: 0.7546\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 166s 868us/step - loss: 0.4930 - accuracy: 0.7627 - val_loss: 0.5016 - val_accuracy: 0.7586\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 165s 862us/step - loss: 0.4865 - accuracy: 0.7667 - val_loss: 0.4976 - val_accuracy: 0.7605\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 165s 861us/step - loss: 0.4807 - accuracy: 0.7703 - val_loss: 0.4976 - val_accuracy: 0.7605\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 166s 870us/step - loss: 0.4754 - accuracy: 0.7734 - val_loss: 0.4965 - val_accuracy: 0.7621\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 166s 868us/step - loss: 0.4709 - accuracy: 0.7762 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Saved model to disk\n",
            "Step18: Generating glove embedding matrix...\n",
            "Step19: designing lstm+glove model...\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 150, 100)          80400     \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 1,953,703\n",
            "Trainable params: 161,103\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.5321 - accuracy: 0.7364 - val_loss: 0.4846 - val_accuracy: 0.7714\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 198s 1ms/step - loss: 0.4962 - accuracy: 0.7627 - val_loss: 0.4694 - val_accuracy: 0.7803\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 195s 1ms/step - loss: 0.4859 - accuracy: 0.7690 - val_loss: 0.4597 - val_accuracy: 0.7850\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.4783 - accuracy: 0.7741 - val_loss: 0.4542 - val_accuracy: 0.7878\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.4721 - accuracy: 0.7776 - val_loss: 0.4475 - val_accuracy: 0.7935\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.4663 - accuracy: 0.7810 - val_loss: 0.4414 - val_accuracy: 0.7960\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 197s 1ms/step - loss: 0.4619 - accuracy: 0.7843 - val_loss: 0.4361 - val_accuracy: 0.7993\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 196s 1ms/step - loss: 0.4578 - accuracy: 0.7864 - val_loss: 0.4315 - val_accuracy: 0.8018\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 195s 1ms/step - loss: 0.4546 - accuracy: 0.7879 - val_loss: 0.4300 - val_accuracy: 0.8021\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 195s 1ms/step - loss: 0.4514 - accuracy: 0.7902 - val_loss: 0.4273 - val_accuracy: 0.8041\n",
            "Saved model to disk\n",
            "Step20: designing gru+glove model...\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 32)                12768     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,805,467\n",
            "Trainable params: 12,867\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 116s 607us/step - loss: 0.5642 - accuracy: 0.7141 - val_loss: 0.5403 - val_accuracy: 0.7332\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 115s 603us/step - loss: 0.5250 - accuracy: 0.7456 - val_loss: 0.5259 - val_accuracy: 0.7445\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 116s 608us/step - loss: 0.5191 - accuracy: 0.7506 - val_loss: 0.5240 - val_accuracy: 0.7450\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 116s 605us/step - loss: 0.5134 - accuracy: 0.7542 - val_loss: 0.5181 - val_accuracy: 0.7492\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 116s 604us/step - loss: 0.5074 - accuracy: 0.7575 - val_loss: 0.5144 - val_accuracy: 0.7516\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 116s 607us/step - loss: 0.5034 - accuracy: 0.7605 - val_loss: 0.5112 - val_accuracy: 0.7528\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 116s 604us/step - loss: 0.5002 - accuracy: 0.7622 - val_loss: 0.5072 - val_accuracy: 0.7561\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 116s 604us/step - loss: 0.4974 - accuracy: 0.7642 - val_loss: 0.5053 - val_accuracy: 0.7569\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 115s 602us/step - loss: 0.4959 - accuracy: 0.7648 - val_loss: 0.5050 - val_accuracy: 0.7563\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 116s 604us/step - loss: 0.4936 - accuracy: 0.7664 - val_loss: 0.5004 - val_accuracy: 0.7601\n",
            "Saved model to disk\n",
            "Step21: designing bidirectional+glove model...\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 150, 100)          1792600   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               84480     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,877,467\n",
            "Trainable params: 84,867\n",
            "Non-trainable params: 1,792,600\n",
            "_________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 170s 890us/step - loss: 0.5171 - accuracy: 0.7466 - val_loss: 0.4811 - val_accuracy: 0.7729\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 170s 890us/step - loss: 0.4708 - accuracy: 0.7796 - val_loss: 0.4644 - val_accuracy: 0.7835\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 170s 887us/step - loss: 0.4580 - accuracy: 0.7872 - val_loss: 0.4563 - val_accuracy: 0.7876\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 170s 890us/step - loss: 0.4475 - accuracy: 0.7933 - val_loss: 0.4531 - val_accuracy: 0.7888\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 169s 884us/step - loss: 0.4388 - accuracy: 0.7983 - val_loss: 0.4422 - val_accuracy: 0.7962\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 170s 888us/step - loss: 0.4307 - accuracy: 0.8030 - val_loss: 0.4345 - val_accuracy: 0.8001\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 169s 883us/step - loss: 0.4240 - accuracy: 0.8073 - val_loss: 0.4317 - val_accuracy: 0.8024\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 170s 890us/step - loss: 0.4182 - accuracy: 0.8102 - val_loss: 0.4313 - val_accuracy: 0.8024\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 169s 884us/step - loss: 0.4129 - accuracy: 0.8132 - val_loss: 0.4241 - val_accuracy: 0.8067\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 170s 886us/step - loss: 0.4075 - accuracy: 0.8163 - val_loss: 0.4235 - val_accuracy: 0.8073\n",
            "Saved model to disk\n",
            "Step16: Training parallel network...\n",
            "glove matrix created\n",
            "sswe matrix created\n",
            "model generated\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_11 (Sequential)      (None, 64)           1834840     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_12 (Sequential)      (None, 64)           925740      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           sequential_11[1][0]              \n",
            "                                                                 sequential_12[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 128)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 64)           8256        leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 3)            195         dense_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,769,031\n",
            "Trainable params: 80,131\n",
            "Non-trainable params: 2,688,900\n",
            "__________________________________________________________________________________________________\n",
            "Train on 191384 samples, validate on 47847 samples\n",
            "Epoch 1/10\n",
            "191384/191384 [==============================] - 187s 976us/step - loss: 0.6356 - val_loss: 0.5950\n",
            "Epoch 2/10\n",
            "191384/191384 [==============================] - 186s 970us/step - loss: 0.5764 - val_loss: 0.5461\n",
            "Epoch 3/10\n",
            "191384/191384 [==============================] - 185s 967us/step - loss: 0.5470 - val_loss: 0.5220\n",
            "Epoch 4/10\n",
            "191384/191384 [==============================] - 184s 963us/step - loss: 0.5331 - val_loss: 0.5107\n",
            "Epoch 5/10\n",
            "191384/191384 [==============================] - 185s 966us/step - loss: 0.5245 - val_loss: 0.5033\n",
            "Epoch 6/10\n",
            "191384/191384 [==============================] - 185s 965us/step - loss: 0.5183 - val_loss: 0.4978\n",
            "Epoch 7/10\n",
            "191384/191384 [==============================] - 184s 961us/step - loss: 0.5134 - val_loss: 0.4936\n",
            "Epoch 8/10\n",
            "191384/191384 [==============================] - 184s 964us/step - loss: 0.5096 - val_loss: 0.4903\n",
            "Epoch 9/10\n",
            "191384/191384 [==============================] - 184s 960us/step - loss: 0.5061 - val_loss: 0.4873\n",
            "Epoch 10/10\n",
            "191384/191384 [==============================] - 184s 962us/step - loss: 0.5034 - val_loss: 0.4851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "Loaded model from disk\n",
            "47847/47847 [==============================] - 105s 2ms/step\n",
            "accuracy:  76.86790823936462\n",
            "negative precision:  0.6906211936662606\n",
            "neutral precision:  0.6757332459446174\n",
            "positive precision:  0.7318819188191882\n",
            "negative recall:  0.4990521327014218\n",
            "neutral recall:  0.5332643693023857\n",
            "positive recall:  0.5631459398069278\n",
            "negative f1_score:  0.5794128050937389\n",
            "neutral f1_score:  0.5961045061973764\n",
            "positive f1_score:  0.6365211810012836\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}